import os
from transformers import T5Tokenizer, T5ForConditionalGeneration

model_name = "flax-community/t5-recipe-generation"
tokenizer_name = "t5-base"
save_dir = "./saved_model"

print("ğŸ“¥ Äang táº£i tokenizer...")
tokenizer = T5Tokenizer.from_pretrained(tokenizer_name)

print("ğŸ“¥ Äang táº£i model (Flax â†’ PyTorch)...")
model = T5ForConditionalGeneration.from_pretrained(model_name, from_flax=True)

print(f"ğŸ’¾ Äang lÆ°u model vÃ o: {save_dir}")
model.save_pretrained(save_dir)
tokenizer.save_pretrained(save_dir)
print("âœ… HoÃ n táº¥t lÆ°u model!")

print("\nğŸ‘‰ Giá» báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng model offline tá»« './saved_model'")
